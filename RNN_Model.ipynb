{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled2.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MNaplesDevelopment/ACM-Fake-News/blob/master/RNN_Model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "Ie_9MdkgQjj8",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "from scipy.spatial.distance import cdist\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, CuDNNLSTM, Embedding\n",
        "from keras.optimizers import RMSprop, Adam\n",
        "from tensorflow.python.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.python.keras.preprocessing.sequence import pad_sequences"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "q84a_UXcZb3I",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Load data\n",
        "import pickle\n",
        "with open('real.pkl', 'rb') as f:\n",
        "    real_titles = pickle.load(f)\n",
        "with open('fake.pkl', 'rb') as f:\n",
        "    fake_titles = pickle.load(f)\n",
        "with open('embs.pkl', 'rb') as f:\n",
        "    embs = pickle.load(f)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "wEznWrffZn_u",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Store into array, at this point the titles are still strings.\n",
        "real = np.asarray(real_titles)[:len(fake_titles)]\n",
        "fake = np.asarray(fake_titles)\n",
        "# Create labels for each title, one for fake and 0 for real\n",
        "fake_labels = np.ones(len(fake))\n",
        "real_labels = np.zeros(len(real))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "vt5lB2TSZRiz",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# The embeddings are currently stored in a dictionary and we need to turn it into a 2-D array of size (# words, Embedding Length)\n",
        "# word_to_int will take a word and convert it to it's index into the embedding matrix\n",
        "# int_to_word does the opposite - takes an index and converts it back to a word\n",
        "embedding_matrix = []\n",
        "int_to_word = []\n",
        "word_to_int = {}\n",
        "i = 0\n",
        "for word, emb in embs.items():\n",
        "    embedding_matrix.append(emb)\n",
        "    int_to_word.append(word)\n",
        "    word_to_int[word] = i\n",
        "    i += 1\n",
        "    \n",
        "embedding_matrix.append(np.zeros(100)) # For unknown words we use an array of zeros.\n",
        "embedding_matrix = np.asarray(embedding_matrix)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "TdaNgI-xZbJU",
        "colab_type": "code",
        "outputId": "b13c3645-2ed4-465d-86b5-da32f1c27e99",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "cell_type": "code",
      "source": [
        "print(word_to_int['and'])\n",
        "print(int_to_word[3])\n",
        "print(np.array_equal(embs['and'], embedding_matrix[3]))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "3\n",
            "and\n",
            "True\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "XpXDQgWBaGP7",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Concat fake and real title into 1 array- same with the labels\n",
        "train_data = np.concatenate((real, fake), axis=0)\n",
        "train_labels = np.concatenate((real_labels, fake_labels), axis=0)\n",
        "# \"Randomly\" shuffle data with the same seed to ensure the 2 arrays maintain their parallel relationship\n",
        "np.random.seed(3)\n",
        "np.random.shuffle(train_data)\n",
        "np.random.seed(3)\n",
        "np.random.shuffle(train_labels)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "pSTVqtEYa56d",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Chop off 1000 examples for testing\n",
        "test_data = train_data[train_data.shape[0]-1000:]\n",
        "test_labels = train_labels[train_labels.shape[0]-1000:]\n",
        "train_data = train_data[:train_data.shape[0]-1000]\n",
        "train_labels = train_labels[:train_labels.shape[0]-1000]\n",
        "\n",
        "num_words = len(embs)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "xRJeTnX2av8L",
        "colab_type": "code",
        "outputId": "ebc5e501-e736-4a87-a02d-b68afc6b2645",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "cell_type": "code",
      "source": [
        "# Converts each title of strings into integers - each word is turned into it's index into the embedding matrix.\n",
        "train_data_tokens = []\n",
        "test_data_tokens = []\n",
        "num_words_missed = 0\n",
        "num_words_found = 0\n",
        "for i in range(train_data.shape[0]):\n",
        "    train_data_tokens.append([])\n",
        "    for word in train_data[i].split():\n",
        "        if word.lower() in embs:\n",
        "            train_data_tokens[i].append(word_to_int[word.lower()])\n",
        "            num_words_found += 1\n",
        "        else:\n",
        "            train_data_tokens[i].append(-1)\n",
        "            num_words_missed += 1\n",
        "for i in range(test_data.shape[0]):\n",
        "    test_data_tokens.append([])\n",
        "    for word in test_data[i].split():\n",
        "        if word.lower() in embs:\n",
        "            test_data_tokens[i].append(word_to_int[word.lower()])\n",
        "            num_words_found += 1\n",
        "        else:\n",
        "            test_data_tokens[i].append(embedding_matrix.shape[0]-1)\n",
        "            num_words_missed += 1\n",
        "print(\"Number of words embedding found %d\" % num_words_found)\n",
        "print(\"Number of words embedding missing %d\" % num_words_missed)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of words embedding found 226332\n",
            "Number of words embedding missing 40147\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "sqH0ID8za2Cj",
        "colab_type": "code",
        "outputId": "2254f87a-3d39-4ac8-ba76-b78e7d2450d6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "cell_type": "code",
      "source": [
        "# Function for taking a title thats been converting into indeces back into strings.\n",
        "print(train_data_tokens[3])\n",
        "int_to_word.append(\"unknown\")\n",
        "def tokens_to_string(tokens):\n",
        "    words = [int_to_word[token] for token in tokens if token != 0]\n",
        "    text = \" \".join(words)\n",
        "    return text\n",
        "print(tokens_to_string(train_data_tokens[3]))\n",
        "# See the how the array of ints gets converted into words."
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[-1, 11548, 9, 341, 18, 61, 14, 2976, 194, 3605, 441, 3911]\n",
            "unknown agony is far from over as syrian general seeks further battles\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "vxtMQ6CYbEbz",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Unimportant\n",
        "num_tokens = [len(tokens) for tokens in train_data_tokens + test_data_tokens]\n",
        "num_tokens = np.asarray(num_tokens)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "DPLJLBuzbNXT",
        "colab_type": "code",
        "outputId": "6a6b7b02-94ec-4fe8-e00e-72435dad09fb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "max_tokens = np.max(num_tokens)\n",
        "print(max_tokens)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "68\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "rnbRl_AObZXz",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Tensorflow requires each title is the same length - that's all this function does.\n",
        "pad = 'pre'\n",
        "train_data_pad = pad_sequences(train_data_tokens, maxlen=max_tokens,\n",
        "                              padding=pad, truncating=pad)\n",
        "test_data_pad = pad_sequences(test_data_tokens, maxlen=max_tokens,\n",
        "                             padding=pad, truncating=pad)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Xo7KEOdPbkgb",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Create Network\n",
        "from keras.layers import Dropout\n",
        "num_words = len(int_to_word)\n",
        "model = Sequential()\n",
        "model.add(Embedding(input_dim=embedding_matrix.shape[0],\n",
        "                   output_dim=embedding_matrix.shape[1],\n",
        "                   input_length=max_tokens,\n",
        "                   weights=[embedding_matrix],\n",
        "                   trainable=False,\n",
        "                   name='embedding_layer'))   \n",
        "model.add(CuDNNLSTM(16, return_sequences=True))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(CuDNNLSTM(8))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "optimizer = Adam(lr=1e-3)\n",
        "model.compile(loss='binary_crossentropy',\n",
        "             optimizer=optimizer,\n",
        "             metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "qUt4PiVhbnpM",
        "colab_type": "code",
        "outputId": "50e7690d-3701-4139-ec65-8c0772d12db6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 340
        }
      },
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_layer (Embedding)  (None, 68, 100)           3604700   \n",
            "_________________________________________________________________\n",
            "cu_dnnlstm_9 (CuDNNLSTM)     (None, 68, 16)            7552      \n",
            "_________________________________________________________________\n",
            "dropout_9 (Dropout)          (None, 68, 16)            0         \n",
            "_________________________________________________________________\n",
            "cu_dnnlstm_10 (CuDNNLSTM)    (None, 8)                 832       \n",
            "_________________________________________________________________\n",
            "dropout_10 (Dropout)         (None, 8)                 0         \n",
            "_________________________________________________________________\n",
            "dense_5 (Dense)              (None, 1)                 9         \n",
            "=================================================================\n",
            "Total params: 3,613,093\n",
            "Trainable params: 8,393\n",
            "Non-trainable params: 3,604,700\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Rr0Q9H9fbrhL",
        "colab_type": "code",
        "outputId": "3ba3a324-a12d-465c-9fa5-0ef1cf3107a5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        }
      },
      "cell_type": "code",
      "source": [
        "# Train\n",
        "%%time\n",
        "model.fit(train_data_pad, train_labels,\n",
        "         validation_split=0.05, epochs=3, batch_size=64)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 22615 samples, validate on 1191 samples\n",
            "Epoch 1/3\n",
            "22615/22615 [==============================] - 10s 459us/step - loss: 0.5595 - acc: 0.7077 - val_loss: 0.4044 - val_acc: 0.8136\n",
            "Epoch 2/3\n",
            "22615/22615 [==============================] - 10s 423us/step - loss: 0.3946 - acc: 0.8167 - val_loss: 0.3531 - val_acc: 0.8354\n",
            "Epoch 3/3\n",
            "22615/22615 [==============================] - 10s 424us/step - loss: 0.3513 - acc: 0.8399 - val_loss: 0.3170 - val_acc: 0.8556\n",
            "CPU times: user 24 s, sys: 6.6 s, total: 30.6 s\n",
            "Wall time: 30.4 s\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f950f8ec7b8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 95
        }
      ]
    },
    {
      "metadata": {
        "id": "AycXv817buNz",
        "colab_type": "code",
        "outputId": "f9ea1120-7d91-419d-eda9-0dccf9ed8c77",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "# Test on testing data\n",
        "result = model.evaluate(test_data_pad, test_labels)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1000/1000 [==============================] - 0s 305us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "q9hvszMvdEcD",
        "colab_type": "code",
        "outputId": "1ab86142-0aae-42af-c805-20caa03d5b6c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "print(\"accuracy: {0:.2%}\".format(result[1]))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "accuracy: 86.80%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "caY-CyZcdGB0",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "title = np.asarray(['US Suspends Nuclear Arms Control Treaty With Russia'.lower()])\n",
        "real_or_fake = 'real'\n",
        "label = \"0\" if real_or_fake == 'real' else '1'\n",
        "wrong = 'real' if real_or_fake == 'fake' else 'fake'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "UQ47oo2VfvyN",
        "colab_type": "code",
        "outputId": "a63bcd30-735d-4f58-985b-29f41e0c961f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "cell_type": "code",
      "source": [
        "num_words_found = 0\n",
        "num_words_missed = 0\n",
        "title_tokens = []\n",
        "for i in range(title.shape[0]):\n",
        "    title_tokens.append([])\n",
        "    for word in title[i].split():\n",
        "        if word in embs:\n",
        "            title_tokens[i].append(word_to_int[word.lower()])\n",
        "            num_words_found += 1\n",
        "        else:\n",
        "            title_tokens[i].append(-1)\n",
        "            num_words_missed += 1\n",
        "print(num_words_missed)\n",
        "print(num_words_found)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0\n",
            "8\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "1t25dD4vgPMN",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "title_pad = pad_sequences(title_tokens, maxlen=max_tokens,\n",
        "                              padding=pad, truncating=pad)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "szZdgfKEgk8N",
        "colab_type": "code",
        "outputId": "9a2052c9-ed8d-4c5c-e9ac-fd915417ffd0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "result = model.evaluate(title_pad, np.array([label]))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\r1/1 [==============================] - 0s 8ms/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "0PDS7XGuhLmV",
        "colab_type": "code",
        "outputId": "d3f95254-d5b7-460c-e9b1-ba688740a377",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "cell_type": "code",
      "source": [
        "print(\"accuracy: {0:.2%}\".format(result[1]))\n",
        "print('Prediction: ' + real_or_fake if result[1] == 1 else wrong)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "accuracy: 0.00%\n",
            "fake\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "tpePcRfEji33",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}